{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Машинное обучения для текстов\n",
    "\n",
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "\n",
    "### Описание данных\n",
    "\n",
    "Столбец *text* в содержит текст комментария, а *toxic* — целевой признак.\n",
    "\n",
    "#### Часть 1. [Подготовка](#part1)\n",
    "* [1. Импорт библиотек.](#part1.1)\n",
    "* [2. Загрузка и подготовка данных](#part1.2)\n",
    "\n",
    "#### Часть 2. [Обучение](#part2)\n",
    "* [2.1 Решающее дерево](#part2.1)\n",
    "* [2.2 Логистическая регрессия](#part2.2)\n",
    "* [2.3 Метод опорных векторов (SVM)](#part2.3)\n",
    "\n",
    "#### Часть 3. [Предсказание](#part3)\n",
    "\n",
    "#### Часть 4. [Общий вывод](#part4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part1'></a>\n",
    "# 1. Подготовка\n",
    "<a id='part1.1'></a>\n",
    "## 1.1 Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "import spacy\n",
    "import re\n",
    "from spacy.lang.en import English\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part1.2'></a>\n",
    "## 2. Загрузка и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "data.info()\n",
    "#\n",
    "corpus = data['text'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим функцию для подготовки текста. Она удаляет из текста все символы, кроме букв, пробелов и апострофов. Далее, с помощью библиотеки Spacy, лемматизирует полученный текст и удаляет из лемм стоп-слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = English()\n",
    "def prepare_text(text):\n",
    "    # очистка\n",
    "    cleared_text = \" \".join(re.sub(r'[^a-zA-Z\\' ]', ' ', text).split())\n",
    "    # лемматизация\n",
    "    lemmatized = [token.lemma_ for token in lemmatizer(cleared_text)]\n",
    "    # стоп-слова\n",
    "    filtered_and_lemmatized_list = []\n",
    "    for word in lemmatized:\n",
    "        lexeme = lemmatizer.vocab[word]\n",
    "        if lexeme.is_stop == False:\n",
    "            filtered_and_lemmatized_list.append(word)\n",
    "    \n",
    "   \n",
    "    filtered_and_lemmatized = \" \".join(filtered_and_lemmatized_list)\n",
    "    \n",
    "    return filtered_and_lemmatized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходный текст: Explanation\n",
      "Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\n",
      "Очищенный и лемматизированный текст без стоп-слов: Explanation edits username Hardcore Metallica Fan reverted vandalisms closure GAs voted New York Dolls FAC remove template talk page -PRON- retired\n"
     ]
    }
   ],
   "source": [
    "print(\"Исходный текст:\", corpus[0])\n",
    "print(\"Очищенный и лемматизированный текст без стоп-слов:\", prepare_text(corpus[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применяем функцию на весь датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(corpus)):\n",
    "    corpus[i] = prepare_text(corpus[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобьем датасет на тренировочную и тестовую выборки. Посчитаем для них TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы: (127656, 147963)\n",
      "Размер матрицы: (31915, 147963)\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(corpus, data['toxic'], test_size=0.2, random_state=1)\n",
    "\n",
    "count_tf_idf = TfidfVectorizer() \n",
    "\n",
    "tf_idf_train = count_tf_idf.fit_transform(X_train)\n",
    "tf_idf_test = count_tf_idf.transform(X_test)\n",
    "print(\"Размер матрицы:\", tf_idf_train.shape)\n",
    "print(\"Размер матрицы:\", tf_idf_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод\n",
    "\n",
    "Данные загружены и подготовлены. Все комментарии лемматизированы, убраны лишние символы и стоп-слова.\n",
    "Данные разбиты на тренировучную и тестовую выборки, посчитан TF-IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part2'></a>\n",
    "# 2. Обучение\n",
    "<a id='part2.1'></a>\n",
    "## 2.1 Решающее дерево"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false --no-raise-error\n",
    "#пропуск выполнения ячейки\n",
    "%%time\n",
    "model_dt = DecisionTreeClassifier(random_state=1)\n",
    "model_params = {\n",
    "            'max_depth': [i for i in range(1,200)],\n",
    "            'min_samples_split' : [i for i in range(2,200)],\n",
    "            'min_samples_leaf' : [i for i in range(1,200)],\n",
    "}\n",
    "\n",
    "rs_dt = RandomizedSearchCV(model_dt, model_params, scoring='f1', cv=5,\n",
    "                           n_jobs=-1,n_iter=100,random_state=1)\n",
    "\n",
    "search_rs_dt = rs_dt.fit(tf_idf_train,y_train)\n",
    "\n",
    "print('Лучшие гиперпараметры:')\n",
    "print(search_rs_dt.best_estimator_)\n",
    "print('Лучший F1:')\n",
    "print('{:.3f}'.format(search_rs_dt.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dt = DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
    "                       max_depth=121, max_features=None, max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=6, min_samples_split=199,\n",
    "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
    "                       random_state=1, splitter='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part2.2'></a>\n",
    "## 2.2 Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false --no-raise-error\n",
    "#пропуск выполнения ячейки\n",
    "%%time\n",
    "model_lr = LogisticRegression(max_iter=1500, random_state=1)\n",
    "model_params = {\n",
    "            'C': [1, 10, 15, 20],\n",
    "            'penalty':['none', 'l2'],\n",
    "            'solver' : ['newton-cg', 'lbfgs', 'liblinear']\n",
    "}\n",
    "\n",
    "rs_lr = RandomizedSearchCV(model_lr, model_params, scoring='f1', cv=3,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "search_rs_lr = rs_lr.fit(tf_idf_train,y_train)\n",
    "\n",
    "print('Лучшие гиперпараметры:')\n",
    "print(search_rs_lr.best_estimator_)\n",
    "print('Лучший F1:')\n",
    "print('{:.3f}'.format(search_rs_lr.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = LogisticRegression(C=15, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=2000,\n",
    "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
    "                   random_state=1, solver='liblinear', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part2.3'></a>\n",
    "## 2.3 Метод опорных векторов (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false --no-raise-error\n",
    "#пропуск выполнения ячейки\n",
    "model_svm = svm.SVC(random_state=1)\n",
    "model_params = {\n",
    "            'C': [0.01, 0.1, 1, 10, 100, 1000],\n",
    "            'kernel' : ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "            'gamma': [1, 0.1, 0.01, 0.001]\n",
    "}\n",
    "\n",
    "rs_svm = RandomizedSearchCV(model_svm, model_params, scoring='f1', cv=3,\n",
    "                           n_jobs=-1, n_iter=10)\n",
    "\n",
    "search_rs_svm = rs_svm.fit(tf_idf_train,y_train)\n",
    "print('Лучшие гиперпараметры:')\n",
    "print(search_rs_svm.best_estimator_)\n",
    "print('Лучший F1:')\n",
    "print('{:.3f}'.format(search_rs_svm.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svm = svm.LinearSVC(C=1, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод\n",
    "\n",
    "Были подобраны оптимальные гиперпараметры для трех моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "||Модель решашающего дерева|Логистическая регрессия|Метод опорных векторов|\n",
    "|-|-|-|-|\n",
    "| F1 на тренировочных данных|0.734|0.756|0.759|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part3'></a>\n",
    "# 3. Предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель:  DecisionTreeClassifier\n",
      "F1: 0.736\n",
      "Время обучения: 33.36553359031677 секунд\n",
      "Время предсказания: 0.024006128311157227 секунд\n",
      "Модель:  LogisticRegression\n",
      "F1: 0.782\n",
      "Время обучения: 1.354809284210205 секунд\n",
      "Время предсказания: 0.003000974655151367 секунд\n",
      "Модель:  LinearSVC\n",
      "F1: 0.788\n",
      "Время обучения: 0.6851546764373779 секунд\n",
      "Время предсказания: 0.002001047134399414 секунд\n"
     ]
    }
   ],
   "source": [
    "for model in [model_dt,model_lr,model_svm]:\n",
    "    time0 = time.time()\n",
    "    model.fit(tf_idf_train, y_train)\n",
    "    time1 = time.time()\n",
    "    predicted = model.predict(tf_idf_test)\n",
    "    time2 = time.time()\n",
    "    \n",
    "    print('Модель: ', str(model).split('(')[0])\n",
    "    print('F1: {:.3f}'.format(f1_score(y_test,predicted)))\n",
    "    print(\"Время обучения: %s секунд\"%(time1 - time0))\n",
    "    print(\"Время предсказания: {} секунд\".format(time2 - time1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "||Модель решашающего дерева|Логистическая регрессия|Метод опорных векторов|\n",
    "|-|-|-|-|\n",
    "| Время обучения, с |33.36|1.354|0.685|\n",
    "| Время предсказания, с |0.024|0.003|0.002|\n",
    "| F1 на тестовых данных |0.736|0.782|0.788|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part4'></a>\n",
    "# 4. Общий вывод\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате работы были изучены и подготовлены данные с пользовательскими описаниями товаров. Проведена лемматизация, убраны стоп-слова.\n",
    "\n",
    "Даннные поделены на обучающую и тестовую выборки, для каждой вычислены значения TF-IDF.\n",
    "\n",
    "Было обучено три модели (решающее дерево, логистическая регрессия, опорные векторы) и методом случайного поиска были подобраны оптимальные гипермапараметры.\n",
    "\n",
    "Все обученные модели были поверены на тестовой выборке.\n",
    "\n",
    "Требуемое значение F1 (>0.75) было достигнуто на двух моделях из трех.\n",
    "\n",
    "Самым лучшим качеством (F1 = 0.788) обладает модель метода опорных векторов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
